{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a simple GAN\n",
    "Using a [video by Aladdin Persson](https://www.youtube.com/watch?v=OljTVUVzPpM) as a guide to creating a Basic GAN which uses the [MNIST](https://deepai.org/dataset/mnist) (A dataset which contains 70,000 images of 28*28 handwritten digits) dataset to train a fully connected GAN to produce images of handwritten digits. I will also be researching PyTorch and why it is widely used as a deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn # Neural network functionality\n",
    "import torch.optim as optim # Optimizer function provides different optimizers e.g. Stochastic Gradient Descent, Adam\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets # Allows us to download and use different datasets in this case MNIST\n",
    "from torch.utils.data import DataLoader # Used in training to iterate through the data\n",
    "import torchvision.transforms as transforms # Provides a variety of transformations for our data\n",
    "from torch.utils.tensorboard import SummaryWriter  # Provides a GUI so that we can analyse results easily in training\n",
    "import time\n",
    "import matplotlib.pyplot as plt # Used to plot anything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import basic PyTorch functions to the program. Looking through the [docs](https://pytorch.org/docs/stable/index.html) gave me a better idea of the specific functions of the program. I researched each import and added comments next to them for clarity. importing packages at the start is like gathering all the cooking ingredients you'll need before you begin cooking - it prepares you with everything required and avoids disruptions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),  # normalize inputs to [-1, 1] so make outputs [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines two neural networks - a Discriminator and a Generator.\n",
    "\n",
    "The Discriminator is like a teacher trying to detect forged handwritten numbers. It uses pattern recognition techniques and deep learning. Specifically, it has convolutional layers that act as feature detectors, scanning the input image for shapes and patterns like an eye. It looks at the strokes, curves, sizes etc. to distinguish real from fake. \n",
    "\n",
    "The dense layers then act more like the logic and decision making part of the brain, taking what was extracted by the convolutional layers and predicting the probability that the writing is real or forged.\n",
    "\n",
    "The Generator is like a student trying to carefully forge handwritten numbers. It uses generative modeling techniques to replicate real handwriting. The dense layers act more like imagination, taking random noise and expanding it to forged image dimensions.\n",
    "\n",
    "The convolutional transpose layers then add in the details, transforming that rough outline into a realistic image with appropriate textures and variations in strokes, size etc.\n",
    "\n",
    "The forward passes show how each network processes the images/noise through the layered computations to produce the Discriminator's prediction or Generator's forged image output.\n",
    "\n",
    "By competing against each other, the networks evolve - the Generator gets better at producing convincing forgeries, while the Discriminator gets better at seeing through them. This adversarial process trains the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 3e-4\n",
    "z_dim = 64\n",
    "image_dim = 28 * 28 * 1  # 784\n",
    "batch_size = 30\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables are what are known as **Hyperparameters**. They are parameters used in the optimizer, the creation of the neural network and the training process. The hyperparamaters in my code include. These parameters are not used inside the neural network:\n",
    "- ***device*** - Choose which device is used, GPU (cuda) or CPU\n",
    "- ***lr*** - The **learning rate** also called step size is a paramater for the optimiser which is multiplied by the gradient in the gradient descent algorithm to determine the next point\n",
    "- ***image_dim*** - Dimensions of the input image or the number of neurons in the first layer of the discriminator\n",
    "- ***z_dim*** - Dimension of the Latent noise or the number of neurons in the first layer of the generator\n",
    "- [***batch_size***](https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network#153535) -  The batch size defines the number of samples that will be propagated through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(image_dim).to(device)\n",
    "gen = Generator(z_dim, image_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"C:\\\\Users\\\\mvpco\\\\Documents\\\\School stuff\\\\GAN\\\\dataset/\", transform=transforms, download=False)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")   \n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator and generator and optimizers for each network and loss are initialized. The MNIST dataset is downloaded and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))W\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad() # \n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last block of code and perhaps the most important is the training loop. This loop is iterated for the chosen number of Epochs. In each epoch, latent noise is generated and fed into the generator network and the output is stored. The output of the generator is then fed into the discriminator which outputs the probability of the image being real or generated. The loss for each output is calculated and used for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title(\"Time taken to complete an Epoch\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Time (s)\")\n",
    "# plt.axis([0, 9, 0, 20])\n",
    "# plt.plot(epoch_nums, epoch_time_cuda, label=\"GPU - RTX 3050 Ti\")\n",
    "# plt.plot(epoch_nums, epoch_time, label=\"CPU - Ryzen 7 5800H\")\n",
    "# plt.legend(loc='lower center')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3226585472a06c598dfa09e82eb7bd2822a77ef3b52edcc2f550a8000bbf5d90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
