<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Efficient Training</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="e935247a-6f6a-4dbf-a675-26e4c6c81c6a" class="page sans"><header><div class="page-header-icon undefined"><img class="icon" src="https://www.notion.so/icons/hourglass_yellow.svg"/></div><h1 class="page-title">Efficient Training</h1></header><div class="page-body"><p id="0a3a9c32-7102-43ee-9967-ca26c73c50be" class="">Whilst I waited for my neural network to finish training, I could not help but think how slow it was! I decided to use that time to research what is happening during the training process and how I can make it faster.</p><p id="4cb831ca-d03f-470b-a7ab-6d86ce1e54d5" class="">Source: <a href="https://towardsdatascience.com/how-do-we-train-neural-networks-edd985562b73"><strong>How do we ‚Äòtrain‚Äô neural networks ?</strong></a></p><p id="60da9eab-2777-455a-845b-86fed6a0e62d" class="">Reliability:<div class="indented"><p id="d343818d-b631-420d-8de2-698e58d354c6" class="">The source is a blog on medium in the ‚ÄòTowards data science‚Äô section published by Vitaly Bushaev who is a Deep Learning engineer. The blog is a detailed explanation on how neural networks are trained from a heavily mathematical perspective, it is relevant to my research as knowing the maths can help me infer why training requires heavy computation.   The writer has 1.4k followers which is impressive on a platform like Medium and further solidifies the reliability of the Blog. As most of the authors points are backed up by mathematical formulas and explanations, it is easy to verify the reliability by further research into the topic. At the end of the blog the author links credible sources he used to learn about neural networks and make the blog.</p></div></p><p id="a99014fe-0d26-44b3-a88a-76e9bd22d8b5" class="">
</p><p id="63beb5f8-d7a1-42ea-aa50-1efefb8ca3ab" class="">
</p><h3 id="8c92d9c7-6999-4576-a673-01b7ff593f4c" class="">Why it takes time to train a neural network</h3><p id="ecf4d630-2f32-41d0-973c-de4f4f83a492" class="">During training, the neural network uses a mathematical calculation of the difference between the neural networks prediction and the actual values. This calculation also known as the loss function is a measure of how good the neural network is predicting values. One of the most basic Loss functions is the Mean Squared Error ( MSE )</p><p id="521b0c13-8c96-43e1-a66b-71e4ebd17498" class="">
</p><p id="e6d75571-f1cd-419b-802a-a97527b69315" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mo stretchy="false">(</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo stretchy="false">)</mo><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>‚àí</mo><msub><mi>x</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MSE = (\frac{1}{n})\sum_{i=1}^{n}(y_{i} - x_{i})^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">MSE</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.845108em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">‚àë</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">‚àí</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span><span>Ôªø</span></span></p><p id="f0226a94-a2fe-473b-8969-dff15a268c2c" class="">
</p><p id="9d485705-b31c-46a7-b6e4-e63657268703" class=""> The neural network uses the loss to update the weights and biases of the neural network so that it may yield results that output a lower loss and produce predictions that are closer to the true value. In order to find weights and biases that yield better results, an algorithm called an optimiser is used. An optimiser creates a vector of partial derivatives whose elements contain the derivatives with respect to each weight and bias. This tells the optimiser how much the loss function will change when each weight and bias is altered. This is useful as the Optimiser can use this to change the weights and biases in order to minimise the loss function.</p><p id="50f3d2b4-1e27-46be-acd3-f1190a37ceec" class="">
</p><p id="6bd7cc75-fd33-46b7-b9ff-c80f449dae08" class="">This would all be very easy for a computer to do it if it was not for the vast amount of weights and biases the neural network has. This means a large amount of processing power is needed for the optimiser to do its job hence why it takes a long time to train the neural network</p><p id="d1b9ac95-1f74-4f6f-a499-173db1909bbc" class="">
</p><p id="887327e3-318f-4290-9b73-8f4153ee0cd9" class="">Now that I have a good understanding of why training a neural network is time consuming, I will delve further into this topic by researching how I can save time by making training faster</p><p id="45b3f792-15eb-48db-b64e-8c3106b39cb5" class="">
</p><h3 id="130c1023-fec1-411d-8eae-dda54feeb63c" class="">Making training Faster üöÖ</h3><p id="b9819a8f-27ed-40ca-94db-ca994f1dd8a3" class="">One thing that can be understood easily about neural networks is that they are <em><em><em><em><em><em><em><em>very parallel</em></em></em></em></em></em></em></em>.</p><figure id="e61addc4-d666-431b-b6e3-e1ad5d77bce5" class="image"><a href="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled.png"><img style="width:336px" src="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled.png"/></a></figure><p id="66d27712-87dc-4cc6-a9b2-d2d19314fdea" class=""> As each neuron is independent of other neurons in the same layer, computations in a neural network can be executed independently of each other concurrently. In other words we can take advantage of parallel computing. Each CPU has cores from which 1 instruction can be executed at once. This means a CPU with 16 cores can execute more instructions per second compared to an 8 core CPU. From this we can conclude that the number of cores in the CPU and the speed at which training is completed have a positive correlation. Therefore the only way I can make training faster is to increase the number of cores in my CPU (This is not possible unless I invest into a higher core count CPU) ?</p><p id="acff8a33-b3d0-44d2-8ec8-da125debadf3" class="">
</p><p id="6f015423-9898-4436-ae0e-a1a43917ba94" class="">Source: <a href="https://towardsdatascience.com/why-deep-learning-uses-gpus-c61b399e93a0">Why Deep Learning uses GPUs</a></p><p id="c7b476da-1b8e-4890-aa4b-e9b4f9219e0a" class="">Reliability:<div class="indented"><p id="a8a39210-516e-4ffd-bc9a-93168fcdb246" class="">The author of the blog is a qualified software engineer who has studied at MIT. I chose to use this blog as it provides the resources he uses at the end to showing that his points are factual. The evidences and links he uses include GPU manufacturers such as nvidia which further emphasises the reliability of the </p></div></p><p id="8f20b569-edca-4a48-b35e-ba6b8707f333" class="">
</p><p id="c155c892-97ab-4b63-82a9-4d25104d43b4" class="">
</p><p id="9319f399-7e69-4ea0-901c-4998408143b0" class="">This is where the GPU comes in. The Graphics Processing Unit has a lot more cores than the CPU meaning you can run many computations on each core at the same time which would reduce processing time. The GPU is also more suited for specialised computing compared to the CPU which is better for general computing. My device contains a mid range GPU (RTX 3050 ti) which has a total of <a href="https://www.notebookcheck.net/Performance-Review-Nvidia-GeForce-RTX-3050-Ti-Laptop-GPU.539010.0.html">2560 CUDA cores</a> which is far greater than the 16 general computation cores of my Ryzen CPU. Running the training on the GPU will theoretically increase the speed at which the program runs. </p><p id="e9e94032-00de-4952-8af6-8eff2e74f2c6" class="">
</p><h2 id="e4e50629-a10a-424d-a0fa-ef3d5bf86e40" class="">Using the GPU</h2><h3 id="f28d3b13-896b-4cf6-ab20-21b600fbefdd" class="">Installing required software</h3><p id="83c2e688-6777-4e9b-8841-91c2aa9ba5a4" class="">In order to utilise the GPU I had to install the correct software so that python and PyTorch is able to interact with my GPU. My device contains an Nvidia GPU which uses a technology called CUDA. </p><blockquote id="d9d44787-19d8-4b13-bbe2-a65428f37f9e" class=""><strong>nvidia (2022)</strong> <em>‚ÄúCUDA is NVIDIA‚Äôs parallel computing architecture that enables dramatic increases in computing performance by harnessing the power of the GPU (graphics processing unit)‚Äù</em>  <a href="https://www.nvidia.com/en-gb/geforce/technologies/cuda/technology/">CUDA Technology | Geforce</a>  (Last accessed: <time>@October 31, 2022</time> )</blockquote><p id="4420c93c-254d-46ad-a036-e8ece1742aff" class="">I installed the correct <a href="https://developer.nvidia.com/cuda-downloads?target_os=Windows&amp;target_arch=x86_64&amp;target_version=11&amp;target_type=exe_network">CUDA software version</a> as indicated in the <a href="https://pytorch.org/get-started/locally/">PyTorch </a>website and also the python packages with the pip command from the <a href="https://pytorch.org/get-started/locally/">PyTorch </a>website</p><pre id="eb7d89e9-51fb-4e78-ad1e-0e211c56af74" class="code"><code>pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117</code></pre><p id="3fe76c4c-dc5f-4d40-8c73-81244c42122f" class="">After I installed the software, PyTorch was not detecting my GPU as a device, this was confirmed when I executed the is_available method in the cuda class which returns a boolean depending on whether the GPU is in use.</p><div id="7faa7db9-fbc4-45e5-9f49-2f3e1fe1964d" class="column-list"><div id="839b8ae1-e78c-4c0b-b313-448947bd38ba" style="width:56.25%" class="column"><figure id="0280c544-57b3-41ea-82c3-90302023480d" class="image" style="text-align:left"><a href="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled%201.png"><img style="width:384px" src="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled%201.png"/></a></figure></div><div id="daeed277-87c0-4166-b3c5-019add793d00" style="width:43.74999999999999%" class="column"><figure id="33280261-e5f1-4b04-9580-72315db11c74" class="image"><a href="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled%202.png"><img style="width:192px" src="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled%202.png"/></a></figure></div></div><p id="1f1910ad-da11-4f18-b116-2cff94696b57" class="">This problem turned out taking much longer to fix than I thought. My troubleshooting process was as follows</p><ul id="da3538e4-6a37-4f2f-8dd3-84c58eea83e1" class="bulleted-list"><li style="list-style-type:disc">Installing different CUDA versions</li></ul><ul id="3e98117b-82d8-4a43-978b-368f391b4b44" class="bulleted-list"><li style="list-style-type:disc">Installing older Python versions ( when I researched the problem online I discovered that PyTorch normally doesn&#x27;t support newer versions of python)</li></ul><ul id="1b066e2d-85b8-4ac7-aa6e-3825bea6740c" class="bulleted-list"><li style="list-style-type:disc">Using a different computer and a different operating system (Ubuntu 22.04) - This eventually solved the problem.</li></ul><p id="2129e85d-c9d6-49fc-b399-357a7ad54028" class="">The reason why it did not work for me at the start was because of the incorrect order at which the programs were installed, the PyTorch CUDA package must be installed <em><em><em><em><em><em>after </em></em></em></em></em></em>the CUDA toolkit. I learnt from this problem solving process that it is useful to have a test computer for troubleshooting. </p><h3 id="5ea1f728-119c-4a74-bc2f-de64e6c88391" class="">Testing the GPU</h3><p id="9b63a988-85d9-46e0-bcf4-8d6915d465fb" class="">I used the fully connected generative adversial network which uses the MNIST dataset to produce handwritten digits ( This model generates images poorly as it is a fully connected nerual network and not a convolutional neural network ) as the test model to evaluate the training times of both the CPU and GPU. Using the python time package, I recorded the time at the start of each epoch and at the end and calculated the difference which is then appended to an array. I did this for both the CPU and the GPU and used matplotlib to plot the values in the array to visualize the data</p><figure id="5d47e47a-a2c0-4fad-8e83-a8b8de9bd9c2" class="image"><a href="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled%203.png"><img style="width:580px" src="Efficient%20Training%20e935247a6f6a4dbfa67526e4c6c81c6a/Untitled%203.png"/></a><figcaption>GPU - RTX 3050 Ti  CPU - Ryzen 7 5800H  The lower the better</figcaption></figure><p id="4d8e7500-c2ca-4e24-80d4-36c1c186743f" class="">
</p><p id="b82b7152-570c-4ee2-8f31-adb5cf2a5057" class="">From the graph we can see that the CPU is actually completing an Epoch (This just means one iteration of the training loop) faster than the GPU. This was surprising and slightly infuriating considering what I had learnt from my previous research. I knew there had to be some reason for this irregularity</p><p id="70564394-14ec-46e6-8239-66206350492c" class="">
</p></div></article></body></html>